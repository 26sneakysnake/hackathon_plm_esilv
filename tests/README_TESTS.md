# üß™ Suite de Tests - Manufacturing Operations Radar

Documentation compl√®te de la suite de tests de validation.

## üìã Vue d'Ensemble

Cette suite de tests garantit que :
- ‚úÖ Les donn√©es Excel sont correctement charg√©es et exploit√©es
- ‚úÖ L'event log est g√©n√©r√© de mani√®re coh√©rente
- ‚úÖ Toutes les analyses produisent des r√©sultats valides
- ‚úÖ Le workflow complet fonctionne end-to-end
- ‚úÖ Les KPIs sont correctement calcul√©s
- ‚úÖ Les recommandations sont pertinentes

## üìÅ Structure des Tests

```
tests/
‚îú‚îÄ‚îÄ __init__.py
‚îú‚îÄ‚îÄ README_TESTS.md                 # Ce fichier
‚îú‚îÄ‚îÄ test_data_loader.py             # Tests du chargement des donn√©es
‚îú‚îÄ‚îÄ test_event_log_builder.py       # Tests de g√©n√©ration de l'event log
‚îú‚îÄ‚îÄ test_analysis.py                # Tests des modules d'analyse
‚îú‚îÄ‚îÄ test_integration.py             # Tests d'int√©gration end-to-end
‚îî‚îÄ‚îÄ run_all_tests.py                # Script principal
```

## üöÄ Ex√©cution des Tests

### Option 1 : Tous les tests (Recommand√©)

```bash
# Avec Python
python tests/run_all_tests.py

# Avec Docker
docker-compose run --rm analyzer python tests/run_all_tests.py
```

### Option 2 : Suite sp√©cifique

```bash
# Tests du data loader uniquement
pytest tests/test_data_loader.py -v

# Tests de l'event log uniquement
pytest tests/test_event_log_builder.py -v

# Tests d'analyse uniquement
pytest tests/test_analysis.py -v

# Tests d'int√©gration uniquement
pytest tests/test_integration.py -v
```

### Option 3 : Test individuel

```bash
# Ex√©cuter un test sp√©cifique
pytest tests/test_data_loader.py::TestDataLoader::test_plm_structure -v

# Avec sortie d√©taill√©e
pytest tests/test_data_loader.py::TestDataLoader::test_plm_structure -v -s
```

## üìä Suites de Tests D√©taill√©es

### 1. test_data_loader.py

Valide le chargement et la structure des donn√©es Excel.

**Tests inclus** :
- ‚úÖ `test_files_exist` : V√©rifie que les fichiers Excel existent
- ‚úÖ `test_load_all_data` : V√©rifie que toutes les donn√©es sont charg√©es
- ‚úÖ `test_plm_structure` : Valide la structure du PLM (40 pi√®ces, colonnes requises)
- ‚úÖ `test_mes_structure` : Valide la structure du MES (56 enregistrements)
- ‚úÖ `test_erp_structure` : Valide la structure de l'ERP (150 op√©rateurs)
- ‚úÖ `test_mes_operations` : V√©rifie les op√©rations du MES (20+ op√©rations)
- ‚úÖ `test_erp_qualifications` : V√©rifie les qualifications ERP (10+ types)
- ‚úÖ `test_data_consistency` : V√©rifie la coh√©rence entre sources

**Couverture** :
- Chargement des 3 fichiers Excel
- Validation de toutes les colonnes essentielles
- V√©rification des types de donn√©es
- Coh√©rence inter-fichiers

### 2. test_event_log_builder.py

Valide la g√©n√©ration de l'event log √† partir des donn√©es sources.

**Tests inclus** :
- ‚úÖ `test_operation_sequence` : V√©rifie la s√©quence d'op√©rations (4-8 ops)
- ‚úÖ `test_operation_stats` : Valide les statistiques par op√©ration
- ‚úÖ `test_generate_event_log` : V√©rifie la g√©n√©ration compl√®te
- ‚úÖ `test_event_log_structure` : Valide la structure de l'event log
- ‚úÖ `test_event_log_completeness` : V√©rifie que toutes les pi√®ces passent par toutes les ops
- ‚úÖ `test_rework_logic` : Valide la logique de rework (5-25%)
- ‚úÖ `test_resource_assignment` : V√©rifie l'assignation des ressources
- ‚úÖ `test_time_consistency` : V√©rifie la coh√©rence temporelle
- ‚úÖ `test_data_from_sources` : V√©rifie que les donn√©es viennent bien des sources

**Couverture** :
- G√©n√©ration de l'event log avec 150 pi√®ces
- Validation de toutes les colonnes (16 colonnes)
- Coh√©rence des timestamps
- Tra√ßabilit√© vers les sources (PLM, MES, ERP)

### 3. test_analysis.py

Valide tous les modules d'analyse.

**Tests inclus** :

**ProcessMining** :
- ‚úÖ `test_process_overview` : V√©rifie la vue d'ensemble
- ‚úÖ `test_lead_times` : Valide les calculs de lead time
- ‚úÖ `test_cycle_times` : V√©rifie les temps de cycle

**BottleneckDetector** :
- ‚úÖ `test_detect_bottlenecks_by_wait_time` : D√©tection par temps d'attente
- ‚úÖ `test_detect_bottlenecks_by_wip` : D√©tection par WIP
- ‚úÖ `test_bottleneck_impact` : Calcul de l'impact

**WIPAnalyzer** :
- ‚úÖ `test_wip_by_activity` : Calcul du WIP par activit√©
- ‚úÖ `test_inventory_profile` : Validation de Little's Law
- ‚úÖ `test_flow_efficiency` : Calcul de l'efficacit√© du flux

**ReworkTracker** :
- ‚úÖ `test_rework_rate_by_activity` : Taux de rework par op√©ration
- ‚úÖ `test_rework_impact_on_leadtime` : Impact sur le lead time
- ‚úÖ `test_first_pass_yield` : Calcul du FPY
- ‚úÖ `test_rework_summary` : R√©sum√© complet

**Couverture** :
- 4 modules d'analyse valid√©s
- Tous les KPIs cl√©s v√©rifi√©s
- Coh√©rence math√©matique

### 4. test_integration.py

Tests d'int√©gration end-to-end.

**Tests inclus** :
- ‚úÖ `test_complete_workflow` : Workflow complet de bout en bout
- ‚úÖ `test_data_consistency_through_pipeline` : Coh√©rence des donn√©es
- ‚úÖ `test_kpis_calculation` : Calcul de tous les KPIs
- ‚úÖ `test_output_files_generation` : G√©n√©ration des fichiers de sortie
- ‚úÖ `test_visualizations_generation` : G√©n√©ration des visualisations
- ‚úÖ `test_recommendations_quality` : Qualit√© des recommandations

**Couverture** :
- Pipeline complet : donn√©es ‚Üí analyses ‚Üí optimisation ‚Üí rapports
- Validation de tous les outputs
- Coh√©rence globale du syst√®me

## üìà R√©sultats Attendus

### KPIs Valid√©s

| KPI | Valeur Attendue | Validation |
|-----|----------------|------------|
| **Nombre de pi√®ces** | 150 | Exact |
| **Nombre d'op√©rations** | 8-16 | ‚â• 4 |
| **Lead time moyen** | 0.5-3h | > 0 |
| **Taux de rework** | 5-25% | Entre 0-100% |
| **Nombre de goulots** | 3-10 | > 0 |
| **WIP moyen** | 0.01-5 | > 0 |
| **Flow efficiency** | 0-50% | 0-100% |

### Fichiers Valid√©s

**Rapports** :
- ‚úÖ `outputs/reports/kpis_summary.json`
- ‚úÖ `outputs/reports/bottlenecks_wait_time.csv`
- ‚úÖ `outputs/reports/wip_by_activity.csv`
- ‚úÖ `outputs/reports/rework_rate.csv`
- ‚úÖ `outputs/reports/RAPPORT_FINAL.md`

**Recommandations** :
- ‚úÖ `outputs/recommendations/recommendations.json`
- ‚úÖ `outputs/recommendations/recommendations.md`
- ‚úÖ `outputs/recommendations/optimization_impact.json`

**Visualisations** :
- ‚úÖ `outputs/visualizations/process_map.html`
- ‚úÖ `outputs/visualizations/wip_heatmap.html`
- ‚úÖ `outputs/visualizations/pareto_bottlenecks.html`
- ‚úÖ `outputs/visualizations/gantt_chart.html`
- ‚úÖ Et 4 autres...

## üîç Interpr√©tation des R√©sultats

### Succ√®s Complet (100%)

```
‚úÖ TOUS LES TESTS SONT PASS√âS - SYST√àME VALID√â
```

Tous les modules fonctionnent correctement. Le syst√®me est pr√™t pour la production.

### Succ√®s Partiel (>80%)

```
‚ö†Ô∏è CERTAINS TESTS ONT √âCHOU√â - V√âRIFIER LES D√âTAILS
```

La plupart des fonctionnalit√©s marchent, mais certaines n√©cessitent une attention. Consulter les logs d√©taill√©s.

### √âchec (<80%)

```
‚ùå PLUSIEURS TESTS ONT √âCHOU√â - CORRECTION N√âCESSAIRE
```

Probl√®mes majeurs d√©tect√©s. V√©rifier les logs et corriger avant de continuer.

## üêõ Debugging

### Test √©choue : "Fichiers manquants"

```bash
# V√©rifier que les fichiers Excel sont pr√©sents
ls -la data/raw/

# Copier les fichiers si n√©cessaire
cp path/to/PLM_DataSet.xlsx data/raw/
cp path/to/MES_Extraction.xlsx data/raw/
cp path/to/ERP_Equipes\ Airplus.xlsx data/raw/
```

### Test √©choue : "Event log non trouv√©"

```bash
# G√©n√©rer l'event log
python src/data_processing/event_log_builder.py
```

### Test √©choue : "Fichiers de sortie manquants"

```bash
# Ex√©cuter toutes les analyses
python main.py
```

### Voir les logs d√©taill√©s

```bash
# Ex√©cuter avec verbosit√© maximale
pytest tests/test_integration.py -v -s --tb=long
```

## üìä Rapport de Test

Apr√®s chaque ex√©cution, un rapport est g√©n√©r√© :

**Emplacement** : `outputs/reports/test_report.txt`

**Contenu** :
- Date et heure d'ex√©cution
- R√©sultats par suite de tests
- R√©sum√© global
- Taux de r√©ussite

## üîß Configuration

### Variables d'Environnement

```bash
# D√©finir le niveau de log pour pytest
export PYTEST_LOG_LEVEL=INFO

# D√©finir le mode de sortie
export PYTEST_VERBOSE=1
```

### Options Pytest

```bash
# Arr√™ter au premier √©chec
pytest -x

# Ex√©cuter en parall√®le (n√©cessite pytest-xdist)
pytest -n auto

# G√©n√©rer un rapport de couverture
pytest --cov=src --cov-report=html
```

## üìù Ajouter de Nouveaux Tests

### Template de Test

```python
import pytest

class TestMyFeature:
    """Tests pour ma nouvelle fonctionnalit√©"""

    @pytest.fixture
    def setup(self):
        """Setup pour les tests"""
        # Initialisation
        return data

    def test_my_functionality(self, setup):
        """Test de ma fonctionnalit√©"""
        # Arrange
        expected = ...

        # Act
        result = my_function()

        # Assert
        assert result == expected, "Message d'erreur"
```

### Conventions

- ‚úÖ Utiliser des noms de tests descriptifs
- ‚úÖ Un test = une assertion principale
- ‚úÖ Utiliser des fixtures pour le setup
- ‚úÖ Ajouter des messages d'erreur clairs
- ‚úÖ Tester les cas limites

## üöÄ CI/CD

### GitHub Actions

```yaml
name: Tests

on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2
      - name: Run tests
        run: |
          pip install -r requirements.txt
          python tests/run_all_tests.py
```

### Docker

```bash
# Ex√©cuter les tests dans Docker
docker-compose run --rm analyzer python tests/run_all_tests.py
```

## üìö Ressources

- [Pytest Documentation](https://docs.pytest.org/)
- [Python Testing Best Practices](https://docs.python-guide.org/writing/tests/)
- [Test-Driven Development](https://en.wikipedia.org/wiki/Test-driven_development)

---

**Derni√®re mise √† jour** : 27 novembre 2025

**Mainteneur** : Manufacturing Operations Radar Team
